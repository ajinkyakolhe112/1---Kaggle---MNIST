{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# just train.csv not thinking about others. \n",
    "train_df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "y_actual = train_df['label'].to_numpy()\n",
    "train_df.pop('label')\n",
    "x_actual = train_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yc/sdgc0ftj32z_ctpgsn9ynz440000gn/T/ipykernel_9332/2561250100.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_actual = torch.tensor(x_actual, dtype=torch.float32, requires_grad= False)\n",
      "/var/folders/yc/sdgc0ftj32z_ctpgsn9ynz440000gn/T/ipykernel_9332/2561250100.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_actual = torch.tensor(y_actual, dtype=torch.int64  , requires_grad= False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([784]) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_actual = torch.tensor(x_actual, dtype=torch.float32, requires_grad= False)\n",
    "y_actual = torch.tensor(y_actual, dtype=torch.int64  , requires_grad= False)\n",
    "\n",
    "# mapping to x_actual to y_actual. combining them together. \n",
    "for example in zip(x_actual, y_actual):\n",
    "    print(example[0].shape, example[1].shape)\n",
    "    break\n",
    "\n",
    "dataset_dict = {'x_actual': x_actual, 'y_actual': y_actual}\n",
    "\n",
    "try:\n",
    "    dataset_dict[5]['x_actual']\n",
    "    dataset_dict[5]\n",
    "except RunTimeError:\n",
    "    pass \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BatchSampler',\n",
       " 'ChainDataset',\n",
       " 'ConcatDataset',\n",
       " 'DFIterDataPipe',\n",
       " 'DataChunk',\n",
       " 'DataLoader',\n",
       " 'Dataset',\n",
       " 'DistributedSampler',\n",
       " 'IterDataPipe',\n",
       " 'IterableDataset',\n",
       " 'MapDataPipe',\n",
       " 'RandomSampler',\n",
       " 'Sampler',\n",
       " 'SequentialSampler',\n",
       " 'Subset',\n",
       " 'SubsetRandomSampler',\n",
       " 'TensorDataset',\n",
       " 'WeightedRandomSampler',\n",
       " '_DatasetKind',\n",
       " '__all__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_utils',\n",
       " 'argument_validation',\n",
       " 'dataloader',\n",
       " 'datapipes',\n",
       " 'dataset',\n",
       " 'default_collate',\n",
       " 'default_convert',\n",
       " 'distributed',\n",
       " 'functional_datapipe',\n",
       " 'get_worker_info',\n",
       " 'graph',\n",
       " 'graph_settings',\n",
       " 'guaranteed_datapipes_determinism',\n",
       " 'non_deterministic',\n",
       " 'random_split',\n",
       " 'runtime_validation',\n",
       " 'runtime_validation_disabled',\n",
       " 'sampler']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.utils.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m--> 150\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ajinkya/Documents/Visual Studio Code/0_PROJECTS/2 - Kaggle Digit Competitions/src/13-nov/complete_pipeline.ipynb Cell 4\u001b[0m line \u001b[0;36m9\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=91'>92</a>\u001b[0m \u001b[39m# Train the model for 10 epochs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=92'>93</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=93'>94</a>\u001b[0m     train(model, train_loader, optimizer, loss_fn, epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=95'>96</a>\u001b[0m \u001b[39m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=96'>97</a>\u001b[0m avg_loss, accuracy \u001b[39m=\u001b[39m evaluate(model, test_loader, loss_fn)\n",
      "\u001b[1;32m/Users/ajinkya/Documents/Visual Studio Code/0_PROJECTS/2 - Kaggle Digit Competitions/src/13-nov/complete_pipeline.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, train_loader, optimizer, loss_fn, epoch):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# Train the model for one epoch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         images, labels \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m], data[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39m# Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:130\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m    131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:130\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m    131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    148\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m--> 150\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MNISTModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        # Define the model architecture\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the model\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_fn, epoch):\n",
    "    # Train the model for one epoch\n",
    "    model.train()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        images, labels = data['image'], data['label']\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        # Backward pass and update the parameters\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss every 1000 iterations\n",
    "        if i % 1000 == 0:\n",
    "            print(f'Epoch: {epoch + 1}, Iteration: {i}, Loss: {loss.item()}')\n",
    "\n",
    "def evaluate(model, test_loader, loss_fn):\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, data in enumerate(test_loader):\n",
    "            images, labels = data['image'], data['label']\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            # Update the total loss and accuracy\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Calculate the average loss and accuracy\n",
    "    avg_loss = total_loss / total\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Load the MNIST dataset from Hugging Face Datasets\n",
    "    dataset = load_dataset('mnist')\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    train_dataset, test_dataset = dataset['train'], dataset['test']\n",
    "\n",
    "    # Create PyTorch Dataloader objects for the train and test sets\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    # Define the model and optimizer\n",
    "    model = MNISTModel()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Define the loss function\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train the model for 10 epochs\n",
    "    for epoch in range(10):\n",
    "        train(model, train_loader, optimizer, loss_fn, epoch)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    avg_loss, accuracy = evaluate(model, test_loader, loss_fn)\n",
    "    print(f'Test loss: {avg_loss:.4f}, Test accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m--> 150\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/ajinkya/Documents/Visual Studio Code/0_PROJECTS/2 - Kaggle Digit Competitions/src/13-nov/complete_pipeline.ipynb Cell 5\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m model \u001b[39m=\u001b[39m MNISTModel()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m10\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     train(model, train_loader, optimizer, loss_fn, epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m     evaluate(model, test_loader, loss_fn)\n",
      "\u001b[1;32m/Users/ajinkya/Documents/Visual Studio Code/0_PROJECTS/2 - Kaggle Digit Competitions/src/13-nov/complete_pipeline.ipynb Cell 5\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(model, train_loader, optimizer, loss_fn, epoch):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39m# Train the model for one epoch\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         images, labels \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mimage\u001b[39m\u001b[39m'\u001b[39m], data[\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ajinkya/Documents/Visual%20Studio%20Code/0_PROJECTS/2%20-%20Kaggle%20Digit%20Competitions/src/13-nov/complete_pipeline.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39m# Forward pass\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn(data)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[39m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[39m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[39mreturn\u001b[39;00m collate(batch, collate_fn_map\u001b[39m=\u001b[39;49mdefault_collate_fn_map)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:130\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m    131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:130\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[39mreturn\u001b[39;00m elem_type({key: collate([d[key] \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m batch], collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[39m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m         \u001b[39mreturn\u001b[39;00m {key: collate([d[key] \u001b[39mfor\u001b[39;49;00m d \u001b[39min\u001b[39;49;00m batch], collate_fn_map\u001b[39m=\u001b[39;49mcollate_fn_map) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m elem}\n\u001b[1;32m    131\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(elem, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(elem, \u001b[39m'\u001b[39m\u001b[39m_fields\u001b[39m\u001b[39m'\u001b[39m):  \u001b[39m# namedtuple\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39mreturn\u001b[39;00m elem_type(\u001b[39m*\u001b[39m(collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/utils/data/_utils/collate.py:150\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m             \u001b[39m# The sequence type may not support `__init__(iterable)` (e.g., `range`).\u001b[39;00m\n\u001b[1;32m    148\u001b[0m             \u001b[39mreturn\u001b[39;00m [collate(samples, collate_fn_map\u001b[39m=\u001b[39mcollate_fn_map) \u001b[39mfor\u001b[39;00m samples \u001b[39min\u001b[39;00m transposed]\n\u001b[0;32m--> 150\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(default_collate_err_msg_format\u001b[39m.\u001b[39mformat(elem_type))\n",
      "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.PngImagePlugin.PngImageFile'>"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# Load the MNIST dataset\n",
    "dataset = load_dataset('mnist')\n",
    "\n",
    "# Define the model architecture\n",
    "class MNISTModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTModel, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, 3, 1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, 3, 1, padding=1)\n",
    "        self.fc1 = torch.nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = torch.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = torch.nn.functional.max_pool2d(x, 2)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Create data loaders for the training and test sets\n",
    "train_loader = DataLoader(dataset['train'], batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset['test'], batch_size=32, shuffle=False)\n",
    "\n",
    "# Train the model for 10 epochs\n",
    "model = MNISTModel()\n",
    "for epoch in range(10):\n",
    "    train(model, train_loader, optimizer, loss_fn, epoch)\n",
    "    evaluate(model, test_loader, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
